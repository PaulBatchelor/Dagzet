@2025-08-17#logzet
@14:33 Re-aquainting myself with this repo, hello logzet #logzet #timelog:00:05:25
I have this logging format that I have been using
for the past year or so. It's sort of adhoc, but
I have a few parsers for it. I'm hoping to make
a more established parser for it here. Similar
to dagzet, it'll parse files and return SQLite
code to produce relational databases.
---
I'm hoping to begin by adding a new aux binary
called logzet. I'd like to install it by default
with dagzet.
---
Well, that was pretty painless. Now for the harder
part, setting up the parser.

@14:42 Planning out the parser #timelog:00:17:31
For the most part, parsing is done line-by-line.
---
The start of the line determines what the line is
going to be.
---
An '@' at the start of the line
signifies the start of a block. What follows the @ determines
what kind of block it will be. For now, there are really two
types of blocks: blocks that indicate a date, and ones that
indicate a time.
---
Date Blocks: The format is YYYY-MM-DD?(#(TEXT)) (like my pseudo-regex?).
In the program, this thing sets the current day of the program.
The hashtag adds a tag for the day.
---
Time blocks: HH:MM (TITLE). This creates a log entry at a particular
time. A day block should be made before adding time. Everything following
the the timestamp (plus whitespace) is the title.
---
Titles in the time blocks can have hashtags. These do not get included in the
the actual title name, and should be automatically removed.


@15:20 continued parsing plans (describing the parser) #timelog:00:14:54
Lines that start with "#!" are logzet commands. Typically,
these come right after the line that starts a block,
but I don't think that needs to be the case.
---
The only command that is used currently is "dz", which
links the current log entry to a particular dagzet node.
---
A line that starts with '---', and nothing else, is considered
a break. Typically, I use these to break things into
paragraphs.
---
A line that starts with "===" begins a pre-formatted block, usually
used for code blocks. It preserve all line breaks and spaces until
it finds another lines starting with "===".
---
I think that's most of it?
---
OH! right. Empty lines are ignored.

@15:46 attack plan #timelog:00:31:06
I'm thinking I may have this be a two-pass parsing process.
The first pass tokenizes things by line, the second pass
parses these tokens to build up a more meaningful representation
of the data.
---
Tokenization is pretty straight forward. Use an enum.
Parse text line by line.
---
Plain text content in a block (anything that isn't a block
or metablock), can be stored line by line and merged later.
pre-formatted block starts change the behavior of the line
parser. Once a block starts, every line parsed after that
points becomes a preformatted line until it finds another
corresponding "===", which turns it off.
---
For logs, log entries are grouped by dates, and dates
can be grouped by category.
---
Claude has come up with suggestions for what to call
these things: A "Session" describes a combination of
a "Date" and an optional "Context". A Session contains
a group of log entries associated with that context.
---
Since dagzet support is also going to be wanted here,
there should be something that shows a list of
related nodes (represented as paths).
---
An Entry consists of a list of content chunks. Maybe
these are just called "blocks" (claude suggests this).
I want this log format to also be generalized in
terms of blocks, but that may be overgeneralizing.

@16:26 working out the initial data structures #timelog:00:47:38
I'm just gonna put them in the one file.
---
I'm thinking about source maps. I think the best way to
express this is as a generic struct that wraps
an inner type.
---
Got some initial structs down. Now, I want to create
some From traits for the lower-level statements.

@17:45 some initial From traits #timelog:00:11:12

@19:22 initial boilerplate: got "break" parsed #timelog:00:20:25

@19:43 attempting regex matching for Time #timelog:00:20:16
Ran out of time. Gotta get home.

@2025-08-18#logzet another hub session

@19:31 resuming where I left off, matches for Time #timelog:00:49:57
I got the basic regex working! now I need to add in
hashtags.

@20:21 Now a similar thing for Date #timelog:00:59:41
This will have a title. Might as well have hashtags?
This could be a generic.
---
Got the "context" hashtag working. Now getting the regular tags working?
---
Working!

@21:22 interlude... fix cargo clippy warnings #timelog:00:01:45

@21:25 get commands working #timelog:00:11:21

@22:07 next steps #timelog:00:10:12
There needs to be something that takes a list of
strings, and turns it into a corresponding vector
of Statements. This should be able to handle
comments as well as blocks.
---
A vector of statements, should also be able to be parsed
and turned into a set of sesssions.
---
Entries and sessions should be sorted. Use a BTreeSet?
Or possibly, it might be just good enough to use parsing
order?
---
Figure out best way to convert data into SQLite tables.
Figure out table schema, then make a bunch of insert
statements.
---
Dagzet commands. Get that behavior in.

@2025-08-19#logzet working at home, PLG, Brooklyn
@20:31 Let's see if I can plan out how Statements turn into Sessions #timelog:00:25:40
I've built myself function. Vector of Statements go in,
Vector of Sessions comes out.
---
I want the output list to be in chronological order.
I'm thinking order could be preservered internally with either
a BTreeMap or a BTreeSet, then converted to a Vec at the last minute.
---
The logic would work by keeping track of the last Date (year, month, day, context).
I believe that by default, the BTree will sort things in order that they appear
in the struct. subsequent statements, would then get processed and inserted into
that active slot.
---
Time entries, like Date entries, should be in sorted order as well. Having a BTree
would be nice, but the struct at the end should simplified to be a Vec somehow.
So, I guess there are some intermediates.
---
Two nested BTreeMaps. The Outer Map is for Dates, and each entry in that map
points to an Inner BTreeMap for Time Entries.
---
Date/Time structs need to be split up more because they have
junk in it like titles and tags. Maybe TimeKey and DateKey.
---
Build BTreeMap types for Session and Entry called SessionMap
and EntryMap. EntryMap is an alias for BTreeMap<TimeKey,Block>.
SessionMap is an alias for BTreeMap<DateKey,EntryMap>. Once it
is all populated, they can get converted to regular list of Sessions
which contain a regular list of entries.

@22:02 some initial refactoring to get DateKey and TimeKey #timelog:00:27:12
I also got the initial BTreeMaps set up as well. It
could be refactored further I think, but this is
good enough.

@22:30 First parse test: can days out of order be put in order? #timelog:00:39:25

@2025-08-20
@10:46 examining the existing SQLite code I have. Can I re-use it? #timelog:00:22:29
My SQLite generator code may be flexible enough to accomodate
the needs for my logs table.
---
My SQLite table code might just be flexible enough.
---
Reaquainting myself with the schemas now.
---
Right. I seem to have two parts to my SQLite interface.
There's a "Row", which contains data for a row. This
seems to exist to produce a comma separated set of values
in a specified order. There's a "Table", an opaque value which
gets dynamically constructed. This has the parameters as well
as their names. The Table and Row work together to create
insert statements.
---
Working with this interface, it seems like the path of
least resistance is to convert a list of Sessions
into a list of Rows that represent the SQLite table
representation. From there, the SQLite traits
can be built out.
---
I get the feeling that with a little bit more
work, I could maybe remove the intermediate
"Row" data format, but in many ways this is
simpler and less work since this is already
written out for me.

@11:18 building out a Row, an initial Session to Rows conversion #timelog:00:48:00
There are two kinds of rows actually, a "dayblurb" for the
day with a blurb (does this need to be there if blurb is none?)
and the entries themselves.
---
Working on the initial dayblurb because it's slightly less
work upfront.
---
Now to get some entries populated.

@12:38 continue to populate some entries for the test #timelog:00:18:07
I think I have the initial test set up. Now to implement
the actual code to make the entries

@12:56 implement the actual code to generate the entries #timelog:00:23:57
One thing that I've started doing more is having a single timelog
broken up into blocks. The current SQLite table doesn't
actually support blocks, that's something that gets handled
by the renderer. Moving forward, it would be better to have
this be modelled with the data.
---
For now, only comments will be supported, no preformatted stuff.
I never actually got around to implementing multi-comments
in my ad-hoc implementation. So, this'll mean breaking compatibility
eventually.
---
Tests seem to pass. Does that mean it works?

@13:41 more parser work for converting Statements into Sessions: grouping #timelog:01:03:23
Right, I'm going to work on getting the core logging components
figured out. That's going to be a date header, setting times,
and appending blocks to those times.
---
Going to make it really brittle right now. Overwriting
dates/times will be possible. I will harden later.
What I want to do is make sure the most bare minimum input
yields the correct output. At that point, the implementation
can start being more end to end.
---
dagzet commands will follow up shortly. I think I am going
to break backwards compatibility for this. I really
want more granular support for multiple blocks, and I want
to make it possible to link nodes to particular blocks
instead of just timestamps.
---
At this point, I'm going to assume the parsing is working
correctly? I think the observed behavior for this test
is that grouping is happening as expected for entries.
---
I didn't think about the line breaking logic. Line breaks
are treated as spaces. Empty lines are ignored.
---
Goodness time got away from me.

@15:04 I need to work out line breaking logic for this parser #timelog:00:33:40
Working backwards, I'm hoping this can be as simple as as
joining a vector of strings together.

@18:01 back to getting the grouping right #timelog:00:07:01
The line breaks work, I just didn't factor in the grouping.
