@2025-08-17#logzet
@14:33 Re-aquainting myself with this repo, hello logzet #logzet #timelog:00:05:25
I have this logging format that I have been using
for the past year or so. It's sort of adhoc, but
I have a few parsers for it. I'm hoping to make
a more established parser for it here. Similar
to dagzet, it'll parse files and return SQLite
code to produce relational databases.
---
I'm hoping to begin by adding a new aux binary
called logzet. I'd like to install it by default
with dagzet.
---
Well, that was pretty painless. Now for the harder
part, setting up the parser.

@14:42 Planning out the parser #timelog:00:17:31
For the most part, parsing is done line-by-line.
---
The start of the line determines what the line is
going to be.
---
An '@' at the start of the line
signifies the start of a block. What follows the @ determines
what kind of block it will be. For now, there are really two
types of blocks: blocks that indicate a date, and ones that
indicate a time.
---
Date Blocks: The format is YYYY-MM-DD?(#(TEXT)) (like my pseudo-regex?).
In the program, this thing sets the current day of the program.
The hashtag adds a tag for the day.
---
Time blocks: HH:MM (TITLE). This creates a log entry at a particular
time. A day block should be made before adding time. Everything following
the the timestamp (plus whitespace) is the title.
---
Titles in the time blocks can have hashtags. These do not get included in the
the actual title name, and should be automatically removed.


@15:20 continued parsing plans (describing the parser) #timelog:00:14:54
Lines that start with "#!" are logzet commands. Typically,
these come right after the line that starts a block,
but I don't think that needs to be the case.
---
The only command that is used currently is "dz", which
links the current log entry to a particular dagzet node.
---
A line that starts with '---', and nothing else, is considered
a break. Typically, I use these to break things into
paragraphs.
---
A line that starts with "===" begins a pre-formatted block, usually
used for code blocks. It preserve all line breaks and spaces until
it finds another lines starting with "===".
---
I think that's most of it?
---
OH! right. Empty lines are ignored.

@15:46 attack plan #timelog:00:31:06
I'm thinking I may have this be a two-pass parsing process.
The first pass tokenizes things by line, the second pass
parses these tokens to build up a more meaningful representation
of the data.
---
Tokenization is pretty straight forward. Use an enum.
Parse text line by line.
---
Plain text content in a block (anything that isn't a block
or metablock), can be stored line by line and merged later.
pre-formatted block starts change the behavior of the line
parser. Once a block starts, every line parsed after that
points becomes a preformatted line until it finds another
corresponding "===", which turns it off.
---
For logs, log entries are grouped by dates, and dates
can be grouped by category.
---
Claude has come up with suggestions for what to call
these things: A "Session" describes a combination of
a "Date" and an optional "Context". A Session contains
a group of log entries associated with that context.
---
Since dagzet support is also going to be wanted here,
there should be something that shows a list of
related nodes (represented as paths).
---
An Entry consists of a list of content chunks. Maybe
these are just called "blocks" (claude suggests this).
I want this log format to also be generalized in
terms of blocks, but that may be overgeneralizing.

@16:26 working out the initial data structures #timelog:00:47:38
I'm just gonna put them in the one file.
---
I'm thinking about source maps. I think the best way to
express this is as a generic struct that wraps
an inner type.
---
Got some initial structs down. Now, I want to create
some From traits for the lower-level statements.

@17:45 some initial From traits #timelog:00:11:12

@19:22 initial boilerplate: got "break" parsed #timelog:00:20:25

@19:43 attempting regex matching for Time #timelog:00:20:16
Ran out of time. Gotta get home.

@2025-08-18#logzet another hub session

@19:31 resuming where I left off, matches for Time #timelog:00:49:57
I got the basic regex working! now I need to add in
hashtags.

@20:21 Now a similar thing for Date #timelog:00:59:41
This will have a title. Might as well have hashtags?
This could be a generic.
---
Got the "context" hashtag working. Now getting the regular tags working?
---
Working!

@21:22 interlude... fix cargo clippy warnings #timelog:00:01:45

@21:25 get commands working #timelog:00:11:21

@22:07 next steps #timelog:00:10:12
There needs to be something that takes a list of
strings, and turns it into a corresponding vector
of Statements. This should be able to handle
comments as well as blocks.
---
A vector of statements, should also be able to be parsed
and turned into a set of sesssions.
---
Entries and sessions should be sorted. Use a BTreeSet?
Or possibly, it might be just good enough to use parsing
order?
---
Figure out best way to convert data into SQLite tables.
Figure out table schema, then make a bunch of insert
statements.
---
Dagzet commands. Get that behavior in.

@2025-08-19#logzet working at home, PLG, Brooklyn
@20:31 Let's see if I can plan out how Statements turn into Sessions #timelog:00:25:40
I've built myself function. Vector of Statements go in,
Vector of Sessions comes out.
---
I want the output list to be in chronological order.
I'm thinking order could be preservered internally with either
a BTreeMap or a BTreeSet, then converted to a Vec at the last minute.
---
The logic would work by keeping track of the last Date (year, month, day, context).
I believe that by default, the BTree will sort things in order that they appear
in the struct. subsequent statements, would then get processed and inserted into
that active slot.
---
Time entries, like Date entries, should be in sorted order as well. Having a BTree
would be nice, but the struct at the end should simplified to be a Vec somehow.
So, I guess there are some intermediates.
---
Two nested BTreeMaps. The Outer Map is for Dates, and each entry in that map
points to an Inner BTreeMap for Time Entries.
---
Date/Time structs need to be split up more because they have
junk in it like titles and tags. Maybe TimeKey and DateKey.
---
Build BTreeMap types for Session and Entry called SessionMap
and EntryMap. EntryMap is an alias for BTreeMap<TimeKey,Block>.
SessionMap is an alias for BTreeMap<DateKey,EntryMap>. Once it
is all populated, they can get converted to regular list of Sessions
which contain a regular list of entries.

@22:02 some initial refactoring to get DateKey and TimeKey #timelog:00:27:12
I also got the initial BTreeMaps set up as well. It
could be refactored further I think, but this is
good enough.

@22:30 First parse test: can days out of order be put in order? #timelog:00:39:25

@2025-08-20#logzet Brooklyn
@10:46 examining the existing SQLite code I have. Can I re-use it? #timelog:00:22:29
My SQLite generator code may be flexible enough to accomodate
the needs for my logs table.
---
My SQLite table code might just be flexible enough.
---
Reaquainting myself with the schemas now.
---
Right. I seem to have two parts to my SQLite interface.
There's a "Row", which contains data for a row. This
seems to exist to produce a comma separated set of values
in a specified order. There's a "Table", an opaque value which
gets dynamically constructed. This has the parameters as well
as their names. The Table and Row work together to create
insert statements.
---
Working with this interface, it seems like the path of
least resistance is to convert a list of Sessions
into a list of Rows that represent the SQLite table
representation. From there, the SQLite traits
can be built out.
---
I get the feeling that with a little bit more
work, I could maybe remove the intermediate
"Row" data format, but in many ways this is
simpler and less work since this is already
written out for me.

@11:18 building out a Row, an initial Session to Rows conversion #timelog:00:48:00
There are two kinds of rows actually, a "dayblurb" for the
day with a blurb (does this need to be there if blurb is none?)
and the entries themselves.
---
Working on the initial dayblurb because it's slightly less
work upfront.
---
Now to get some entries populated.

@12:38 continue to populate some entries for the test #timelog:00:18:07
I think I have the initial test set up. Now to implement
the actual code to make the entries

@12:56 implement the actual code to generate the entries #timelog:00:23:57
One thing that I've started doing more is having a single timelog
broken up into blocks. The current SQLite table doesn't
actually support blocks, that's something that gets handled
by the renderer. Moving forward, it would be better to have
this be modelled with the data.
---
For now, only comments will be supported, no preformatted stuff.
I never actually got around to implementing multi-comments
in my ad-hoc implementation. So, this'll mean breaking compatibility
eventually.
---
Tests seem to pass. Does that mean it works?

@13:41 more parser work for converting Statements into Sessions: grouping #timelog:01:03:23
Right, I'm going to work on getting the core logging components
figured out. That's going to be a date header, setting times,
and appending blocks to those times.
---
Going to make it really brittle right now. Overwriting
dates/times will be possible. I will harden later.
What I want to do is make sure the most bare minimum input
yields the correct output. At that point, the implementation
can start being more end to end.
---
dagzet commands will follow up shortly. I think I am going
to break backwards compatibility for this. I really
want more granular support for multiple blocks, and I want
to make it possible to link nodes to particular blocks
instead of just timestamps.
---
At this point, I'm going to assume the parsing is working
correctly? I think the observed behavior for this test
is that grouping is happening as expected for entries.
---
I didn't think about the line breaking logic. Line breaks
are treated as spaces. Empty lines are ignored.
---
Goodness time got away from me.

@15:04 I need to work out line breaking logic for this parser #timelog:00:33:40
Working backwards, I'm hoping this can be as simple as as
joining a vector of strings together.

@18:01 back to getting the grouping right #timelog:00:07:01
The line breaks work, I just didn't factor in the grouping.

@18:12 looking into dagzet logic #timelog:00:37:28
I think the way I did this before was a bit of a hack.
I believe what it did was was make the node a hashtag
with the prefix "dz:". I'd then have code that was able
to search for these nodes associated with messages
and stitch them up.
---
What I want is a more dedicated structure for the job.
Something that actually shows the relationship between
items.
---
Previously, I was only attaching nodes to entries. I'd
like to extend that to be with blocks inside an entry
as well. A more sophisticated command language would
be nice too, but I can think on that one later. Just
full paths and '$' should be good enough.
---
I could probably make an ID system work. The id would
map to a list of node paths. Somehow, this could be something
that could be query-able in a SQL join operation.
---
A potential structure could be an entity list. Anything
that gets made gets added to this list.
---
Any time you'd call the dagzet command, you'd be appending
it to the last entity item on the list.
---
This could be a helpful item in general for things like
source maps, so, I'm included to see how feasible it
would be to construct such a thing.

@18:59 entity list investigations, might need to go full ECS. Is this ECS? #timelog:00:23:48
For starters, get the old way working, which is
the ability to link to the entry. Build an entity
component list but only add entries.
---
Okay. So this might be a non-trivial refactor. I think
I need to reverse the thining. The entity list owns all
the components, and the struct just references it. This
is how an entity component system would work.

@20:12 let's try that entity list #timelog:01:49:07
I'm going timebox this, get some initial scaffolding in.
---
Huh, there's really just three entity types at the end of
the day: Sessions, Entries, and Blocks. Doesn't seem
so bad...
---
To try things out, I'm going to work on making all Blocks references,
and maintaing a list of blocks externally. This should get
the lifetime annotations correct. From there, I can more
generalize this list of blocks into a pool.
---
Okay, it started getting a little hairy there. I tried getting
blocks working for output data structure. But what if it was
for the intermediate data structure (BlockData)? This could
potentially be an internal refactor, might be less damage.
---
It has been an hour. I'm still running into similar borrow
checker woes. Once again, this feels like a dead end.
---
We could try fake pointers and a block arena.
---
Well, the block list works! A good proof of concept.
The way to extend this would be to turn this into
an entity Enum.
---
Okay, I made it a more generic list. It works, but I'm already
seeing the issues of indirection. Once more types get introduced,
everything just becomes vectors of pointers. Sigh.
---
Final thoughts: session "map" needs to be taken into another function
I think. Entity list might another intermediate step. commands might
be a part of the entity list? Statements -> Entities -> Entities + Maps with pointers -> Sessions
data struct (no references or entities), other linked metadata.

@2025-08-21#logzet Brooklyn
@12:06 Back to solving the entity list problem, first restating the problem #timelog:00:13:54
I am opting for a different structure than what currently exists.
The restructuring is going to be needed because it will make it
easier to tie content into dagzet.
---
The restructuring involves building an entity list, where every
possible type of item a log can make lives. Currently that's
Session (a day plus context), Entry (a timestamped log entry in a Session),
and a Block (something attached to an entry, usually text).
The existing structure (a struct outling the tree-structure hierarchy
of the session->entry->block relationships), would be refactored to
link to references from the entity list.
---
The reason why this way is ideal: it would allow building structures
that can easily link entities (referenced by an entity ID) to
groups of nodes. I want to extend the functionality of this linking
system beyond the original implementation I had to make it possible
to not only link to entries, but individual blocks as well.
---
The trouble is, how do we get this to work in such a way that
the borrow checker likes this. Right now, I am testing things
out by making blocks tracked externally. I managed to get fake
pointers working, but this is subpar because types will go away
with that approach, it's all just usizes.
---
I want to try and separate out the construction of the intermediate
data format, which I use to sort out the timestamps for sessions
and entries. Maybe with the right encapsulation I can please the
borrow checker? It's mostly been mutability issues. My lifetime
annotations have been no problem.

@12:23 pulling out sessionmap #timelog:00:07:26
This actually is helpful because it builds an abstraction
barrier of immutability. This new function returns a session
map and an entity list, both of which are immutable by the
time they leave the function. In a way, the Rust Compiler
is forcing us to build these abstractions. Probably a good
thing?

@12:34 now we fight the borrow checker. get blocks to be references #timelog:00:12:19
I get the feeling there might be a trick to this.
---
Here come the lifetime annotations.
---
Okay, the red squigglys are here. The problem has to do with
the way blocks are getting populated with lines. There seems
to be too many "access lines". The way parsing happens is,
text lines are always appended to the last created block.
The way this block is being accessed is through the last
created entity, but this only has a read-only reference.
This should probably be only done via the entity list.
---
Well, I commented out some things. It builds, but some
tests fail. As expected.

@13:11 trying to build an EntityListBuilder #timelog:00:35:41
This will be an interface that can populate a list of entities,
and at the end, I can return a immutable reference
to the list built. Should hopefully encapsulate some of the
mutabiliy issues
---
all write operations will be done through this
interface, instead of indirectly through the
last created entity. It's already assumed that
the last block made will be tied to the last
entity.
---
Sure enough, the moment I add things that return references,
I run into lifetime issues. I think I might
need to encapsulate the session map.
---
I have encapsulated the session map, which hopefully means
later I can move some logic inside the struct methods.
I've added some TODOs. In the meantime, gotta go.

@2025-08-22#logzet Brooklyn, PLG
@11:20 continued work on EntityListBuilder #timelog:01:31:57
I feel like I'm on the right path with encapsulation.
This seems to please the borrow checker.
---
...except some tests aren't passing. I thought I got
that working yesterday. Hmm...
---
looks like the grouping logic is broken.
---
right, I didn't actually implement the methods
for appending stuff to blocks and creating
new blocks.
---
Running into lifetime issues trying to append
the reference to the block to the entry.
---
I'm wondering if I need to group the session
map and the entity list into a struct.
---
I've merged the two things into a struct,
and I'm still getting lifetime issues.
---
There are too many mutable sources. the session
map and entity list can't both be mutable.
---
Can we build a session map, with references, from a read-only
entity list?
---
Or maybe, there's a sort of thing where we use a builder
pattern that appends items to the session map, but the
write is encapsulated in a method.
---
Yeah, that's not going to work either.
---
I'm trying the Statements -> Entities -> SessionData -> Session route,
where the new thing is explicitly making the entities,
THEN making the session data.
---
I'm going back a bit further now. The entity list initial
attempt was flawed from the start.

@12:57 Make entity list an initial intermediate format. NEVERMIND. #timelog:00:29:57
Blow up more old entity list
---
Now to think about this entity list a bit.
---
Entities are something inbetween statements
and the full-on data representations. No
nesting relationships are produced yet.
---
I shouldn't have been going down the path
of references. Learned my mistake here.
---
I'm taking a break.

@14:31 initial scaffolding for entity list #timelog:00:13:54
I've set things up in such a way that the only part in
the pipeline that is changing is what is happening
between line statements and the session map. With
any luck, I should be able to get a session map from this
new entity list.
---
The session map may need to be reworked to compensate for
connections to nodes, but the entity list should position
things in a good place for that because it'll allow easy
access to the last item, and more granular control over
what is being referenced.

@14:29 initial attempt implementing the scaffolding #timelog:00:35:27

@15:07 phew! finally, think about connection to dagzet nodes #timelog:01:07:16
All entities need UUIDs.
---
Map the UUIDs to list of nodepaths.
---
The DZ command is processed with the entity list is being
created.
---
All entities need to have an id now. Enforce this with
traits.
---
WithId trait implemented. DZ commands should work for entries and blocks.

@16:56 I gotta think how this is going to work with SQL tables #timelog:01:01:58
The schemas are going to need to be adjusted
---
Big change is going to be that comment blocks will need to be in their
own table I think. It's possible in the future we mave more kinds
of blocks, but right now it's just comments. sometimes they are
preformatted with line breaks. But the row is going to be identical by the time
it hits SQLite.
---
Later, it might be a good idea to have an entity list table that maps ID values
to entity types for a type lookup. But, in practice, I don't think that sort
of thing is going to be needed for queries (yet).
---
I think an entity table might actually be necessary if I want to append logs to an
existing database like I do with dagzet and dz_nodes.
---
actually, dagzet just inserts the ids as-is without any kind of offset calculation
in the SQLite query (at least, from what I can see). It *is* able to do
id resolution from a path.
---
Am I really just generating my knowledge graph by cramming a shitton of
arguments on the commandline?
---
oh, I see. yeah, my node list has ID values auto-generated from SQLite,
but "position" is a value that gets inserted which I was confusing for
node id. Well, that makes things more interesting.
---
Might need to make the id a string like a timestamp or something. There
are definitely ways to make unique identifiers.
---
YYYY-MM-DD-(CONTEXT)-HH-MM-(CONTEXT)-POS I think is all that's needed.
If you don't supply a unique context, logs can overwrite eachother, but
I think that's fine
---
YYYY-MM-DD-ABCDEFG-HH-MM-ABCDEFG-0FF
---
38322B65-1651-4272-8490-93557971EF6B
---
For context, for the same size of a UUID,
you can have a session AND time with a unique
context tag of 7 characters, and the session can
have 4095 blocks associated with it when position
is encoded in base16 (12-bit number). So, this
might be a perfectly reasonable persistent UUID.

@19:39 More Log UUID thoughts #timelog:00:19:44
Rearticulating the idea.
---
A set of logs are made up of smaller components called entities.
---
Entities connect to eachother in a way that forms a hierarchy
between "Sessions" (a day), "Entries" (times of day), and
"Blocks" (text content that is associated with an entry).
---
Entities can also be connected to dagzet nodes.
---
Different entities have different kind of metadata. In SQL,
the data for the entities gets broken up into tables.
---
These metadata tables need to be able to know which entity
it belongs to. In Dagzet, tables are linked together with
foreign ids, which point back to a master node list.
---
To mirror the dagzet pattern there would need to be an entity
list. Each entity gets an auto assigned row id, as well as
a unique identifier. This row id is what is actually used
as the id (integers are smaller, faster than strings).
The SQLite queries generated use this unique identifier to
look up what the row id is.
---
Thinking the format of this UUID should be YYYY-MM-DD?(-CONTEXT1)/HH-MM?(-CONTEXT2)/POS.
It follws the same path logic as the dagzet nodes. Sessions would only
get the first part of the path, entries would get the first 2 parts,
and blocks would get all three parts.
---
Note that UUID is only required for the SQLite table.
It's not necessary for the intermediate logic. local IDs work just fine.

@19:59 fix up broken test #timelog:00:04:22
I'm changing SessionRows and LogRow.

@20:05 Entity UUIDs for SessionRows #timelog:00:59:20
SessionRows are made from a Session, and the
conversion happens via a From trait.
---
Renaming structs to be more consistent with
my terminology. Previously, I was trying to work
towards an existing schema I was working with. Now,
I think it's more worthwhile to just start over.
This will be better, and it's worth the burn.
The SQLite databases are temporary. The source of truth
are the logs, and those will still work.
---
focusing on getting the entity UUIDs right now.
---
Entity UUIDs work as expected for Sessions and entries. Now I need
to extend it for blocks.
---
Can we make RowEntries embed RowBlocks. What's to stop us from doing that?
Not terribly important for now, but maybe food for thought later.
---
Entries UUIDs work for Sessions, Entries, and Blocks. Seeing
how they look in the tests, it actually looks pretty clean.
I think this is going to be a very helpful format.

@21:06 Configuring the connection table is next #timelog:00:40:20
I added connection rows to SessionRows, but Session
doesn't have the information for connections? Where
am I storing that information?
---
Ah. It's in the entity list. I have not yet decided on how
to get these connections exposed to the Session. Entity IDs
get erased currently.
---
You can make From traits for tuples? Okay that's sick. I can
use that to make a Session from a SessionMap and a DateKey.
---
The from traits make the whole SessionMap -> Session much
easier to read.
---
Oh, I see some complications. If you can connect a node to
the entire session (this is technically possible), you can't
exactly put the connection list inside of a Session as a child.
It needs to exist alongside the Session, so it lives alongside
the session list.
---
So, I got a few structs up. Basically, I want to see if it's possible
to store the list of sessions, and then a list of connections with
a pointer to the entity it belongs to (which could exist in any
of the sessions).
---
Okay, gotta stop. Bed now.

@2025-08-23#logzet Brookln, PLG
A day at the Met. Now, I am post dinner, post dessert, and
post late afternoon caffeinated. Let's see what I can do today.

@19:02 initial attempt at building out a connections list #timelog:00:52:41
There *is* a connections list. It is contained in the
EntityList. It is a map that ties entity id to a list
of dznode paths (strings). I would like to turn this
into a list of things with the dz node path and
the direct reference to that thing.
---
References are hard. I'm going to try a small test.
Can I locally populate a list of references of a particular
type? And if so, can I create a function that generates that
list from a session map?
---
Think I might be just stroking Rust the wrong way. I'm already
running into issues.
---
Claude seems to think I can use hash_map.values().collect()
to make read-only list of referenced values. Let's see if that
actually works.
---
It works! A little clue. But, this is tricky because the items
are nested, so only the sessions appear. We need a flat list.

@19:56 I think I may need a new Session Tree structure #timelog:00:24:25
Basically, the session tree can only made up of references from
the entity list. Maybe just have things made up of indices
from the entity list.
---
Okay. This is the new plan. logzet stuff needs to get moved out of the binary
and broken up into individual files. It is time. I think this code
is officially hard to work through in one place.

@20:23 clean up logzet, put it in a module in the library #timelog:00:49:35
also split up the module into different components
---
I have created a lib.rs file with the logzet stuff as a module, and
that file is being used in the binary called logzet.
---
now to move things.
---
statement.rs
---
entity.rs
---
session.rs: WAY too many imports. clearly need to abstract this
one better. Probably should pull some of this into the top-level
mod.rs function.
---
rows.rs
---
id.rs

@21:54 What's next: the session as a tree of links #timelog:00:14:06
A "Session" can be thought of a tree structure. A session
is composed of Entries, and Entries are composed of Blocks.
---
Our current Session has these data items nested directly.
However, this becomes tricky when any of these components
can link to a list of nodes. So, the idea is to use the
genertated EntityList more directly, and have the Session
be composed of virtual pointers to this EntityList.
---
"virtual pointers" in Rust are just indices, which are
just usize types. I want these indices to be typed
so it's not just a bunch of usizes flying
around.

@2025-08-24#logzet Brooklyn, PLG
@08:35 initial session tree scaffolding #timelog:00:29:05
Going to need typed entity indices. ended up just
making them struct tuples.
---
Added some getters that take in these typed indices
---
fleshing out the session tree struct. This is going
to look a lot like our current session struct, but
with references.
---
Thing I'm going to make a SessionMapBuilder, that
can be generic over either a SessionMap or a SessionTreeMap.

@09:05 Session builder? #timelog:01:53:18
I started coding too quickly. Resetting.
---
Initial SessionBuilder created, no generics.
---
Thinking through how to make things more generic. Generic
enough for the session tree
---
It's helpful to organize, I guess. It's helping me realize
that this might be another dead end, or that I'm further
from my refactoring goals than I expected. How are the indices
going to get inserted?
---
in entities_to_session_map, the entity ID is the index in
the entity list. So, when items are passed into the insert
methods, the id should be passed in as well. This can
be paired with the `with_id` trait I think. With the
current session map stuff, this won't do anything. With
the session tree, it will actually set the indice.
---
ID values have been introduced into the interface. ID data from
the entity list gets proliferated into deeper the system, and if I'm
thinking about it right, it should touch the parts where the actual
tree nodes would be constructed.
---
I now need to direct my attention to traits again. Bottoms up.
Deal with the smaller traits, encapsulate, then work upwards to
the session builder.
---
The lowest level concern is the thing in charge of appending
blocks to an entry. Some kind of method or trait called "append_block"?
---
Or, maybe, just maybe. EntryData is generic over a type?
---
EntryNode and EntryData are so close. But, I think it might
rip up too many things to change EntryData.
---
Trying to top-down this thing and let the compiler tell
me what needs to be finished.
---
My type aliases EntryMap and SessionMap need to go. They
need to be broken down into the BTreeMap KV components. The
key stays the same, the value will change.
---
Managed to barely make EntryData generic.
---
Managed to barely make SessionData generic.

@11:07 continuing with the refactor #timelog:00:48:16
Going to bottoms-up Session Builder with generics.
Make sure it can be generic over blocks, then entries,
then sessions.
---
Okay, that wasn't great. Perhaps it wasn't the best idea
to hop abstractions from BlockData to SessionMap. It
should be completely encapsulated at this point anyways.
---
Going to stab it top down. Make SessionData an alias,
then try to worm that into a generic.
---
Used a phantom data type to make the outer layer generic
syntax work as expected. Had to remove the Default
trait and replace it with an explicit new method,
but that's okay.
---
Now, time to see what breaks when T is actually used.

@12:00 failed again. maybe SessionBuilder needs better encapsulation? #timelog:00:15:00
The methods here have leaky abstractions, which may be
contributing to my poor attempts at refactoring.
---
Maybe use the "inner" pattern. wrap these BTreeMaps into structs,
and add getter methods for those.
---
Well, certainly EntryMap for starters, working bottoms-up.
---
Okay, insert method for EntryMap feels like a nice win.

@12:27 more inner encapsulation #timelog:00:45:53
This block insertion business is drilling down too deep.
---
I still haven't figured out the block encapsulation yet,
but I got session map encapsulated now. Eventually,
block insertion will be encapsulated in an entry,
entry insertion will be encapsulated in session. block
insertion possible from the session maybe? does that
make life better or worse?
---
Got a generic partially working for EntryMap. Should
be fully generic for EntryMap downwards, hardcoded to
BlockData for SessionMap.

@13:24 back to trying to make it generic from top-level #timelog:00:15:00
Let's see what breaks
---
Things need to bubble up more. Blocks need to be inserted
from entries, entries need to be inserted from sessions.
---
Well, that's all the time we have for now. Damn.

@16:38 some traits built on SessionData #timelog:00:31:17
I managed to get insert_entry as a method in the SessionData
struct. But, I think this is going to need to be a trait.
---
Oh my god. This trait issue that was grinding me was a really
easy fix. I was just putting the "where" syntax in the wrong place.
---
Now, do the same for appending a block. Make it a method,
for SessionData then a trait implemented for SessionData.

@17:10 Yet another attempt at generiszing the top-level SessionBuilder #timelog:00:48:35
Let's see what breaks. Hopefully it's a bit less.
---
insert block behavior requires another trait parameter,
can that be removed?
---
It doesn't look like it. BlockData needs to be an actual argument
passed in at the top-level interface.
---
Still pain points with From<Time>.
---
Actually, the pain point is with BlockData. Isn't it always going
to be BlockData? That comes directly from the entity list. I don't
need to make a separate trait for it.
---
I think we did it? I think it's generic?

@17:57 entity list needs to be preserved. fix to make parser pass by reference instead of value #timelog:00:59:04
Sigh. This might actually be a wrinkle.
---
Let's see if I can get the "Date" to work with pass by reference.
---
Ran into lifetime annotation bugs which were weird because I was only
passing by reference. Actually, I was passing by value in the top-level
iterator and passing that value by reference, which was causing the value
to drop.
---
it's a little more copying now, but I think it works.

@19:35 flesh out and test session tree #timelog:00:38:49
I see another problem with my design. The BTreeMaps aren't
fully abstracted away like they should be.
---
Somewhere, I need to be able to provide 3 parameters: data structs
for session, data, and entry. Fill out the traits, and the result should
be an ordered tree of data with those structs.
---
Oh thank god, this seems salvageable. I think I was just
missing a top-level struct for representing the session data.
I chose a bad name for it, but I think it works.
---
EntryData did not need to be generic.

@21:02 Try to build out top-level functions for session tree #timelog:00:40:07
I gotta eliminate SessionData. Or at least shove it down a few levels.
---
It's amazing how complex and ugly this has gotten. I'm pushing
all these abstractions juuusst below the surface, all to
make things feel a little bit better for the fingers
and the brain.
---
Well, it builds. That's the nicest thing I can say. There's
a lot of text being flung around. The abstractions are starting
to blur. It takes effort to maintain something. These
are definitely the wrong abstractions. I'm hoping this
refactor will be worth it.

@21:45 initial construction of SessionTree #timelog:00:15:41
Actually, the final SessionTree hasn't been produced yet.
Only the map has been made.

@22:01 test the SessionTree #timelog:00:28:01
Entity list goes in. Session Tree comes out.
---
Many of the traits are placeholders. I expect this
might fail.
---
Session Tree works! The refactoring almost feels worth it.
But wow, am I tired.

@2025-08-25#logzet Brooklyn, PLG
@09:04 what is left here? #timelog:00:13:42
It feels close now. Last night the so-called "session tree"
tests passed, which means I now have an entity structure
and with it, the ability to connect any of those entities
to dagzet nodes.
---
I could keep adding features and quality of life things,
but I'm running out of time. I need to get the actual
logzet parser to work. end to end. text files go in,
and SQLite commands go out.
---
A session tree needs to be able to generate SQLite rows.
We have this set up for the other session, but not the
session tree. The data should be identical, the means
of accessing it will be different.
---
There needs to be something that reads a file and converts
the lines to statements. This is probably what I'll do last.
---
The SQLite row structures I've been making need to be
converted to actual SQLite code. This shouldn't be too
difficult, as this is re-using components I made for dagzet.
---
The generated SQLite code won't work with the dzbrowse
stuff I've made. I think it's two steps forward one step
back. Progress. But, I will need to address that.
---
I was never fully pleased with the web interface for
dagzet. Finding nodes was still tricky, presentation was
not great either. Also, more important for me moving forward
is to be able to make it easier to make connections between
nodes that are further away. All beyond the scope of logzet
right now though.

@09:22 convert session trees to row data #timelog:00:53:30
rows.rs. Good opportunity to attempt to move some tests
around if possible.
---
LOL. I already did this. So much for that side quest. Onwards.
---
The high level test has been made. This ensures that the the conversion
makes the right number of rows. It does not check that they have
been converted correctly. In fact, I've created a bunch of From
traits that still need to be implemented, with some test stubs
to fill out as well. The TDD will continue until morale improves.

@12:35 Set up From trait for RowEntry #timelog:00:54:48
Uh oh, I have not figured out tags yet have I.
---
Uh oh, I have not figured out how to get the "day" into the SQLite row.
This is actually okay, because the scope is only to one session
node. Just change the From trait to include the session node.
---
Got to think about blocks

@13:53 How do blocks going to work with SQL? #timelog:00:09:54
For Entries, I think there's enough information
to know the top block pointer, and the number of blocks.
---
When blocks are queried, they are going to need to know
which entry they are a part of, and what order they
appear in. Fastest thing is to order by entity ID,
which is determined by the order they were created in.
I don't think the position for a block is explicitely
tracked anywhere.
---
It might make sense to construct the rows data inside
the entry rows data. Somehow, the generated SQL code would
be able to separate out the two. The advantage here is that
the position data could be recorded this way.

@14:11 complete entry blocks test #timelog:00:21:35

@14:33 am I going to have to redo the entry IDs? #timelog:00:05:33
Entry IDs are stored in virtually every row struct type.
Should they be strings for the UUID?
---
No, this is correct. The table that will be generated will
produce a rowid belonging to the entity table. This rowid
will be obtained using a little subquery in the insert that
will find it based on UUID.
---
So, the pipeline goes entity id -> UUID -> row id.a
---
We already have these traits in place, good. I can
move forward to blocks.

@14:39 before blocks, address entry position #timelog:00:09:46
You know, position was also a variable in the EntryRow,
but I just removed it a few hours ago. It's the same problem,
how to track this data?

@14:51 now, blocks #timelog:00:42:02
how will parent id be retrieved? hmm.
---
updated the from trait to include parent id

@15:40 now onto entity list #timelog:01:04:12
My current entity From trait won't wory because
it is using the Entity data directly, and that won't
have any scope. A block entity by itself doesn't know
anyting about which entry it belongs to, or which
entry it belongs to.
---
Realization: This is why we need the entity list AND
the tree that references the entity. The information
the tree gives is the relationships between the entities.
---
I'm scrapping the From trait. I had this notion of making
a list of tuples pointing to the session, entry, and block
indexes. But, that's a lot of overhead. I think it's better
to generate the row UUIds from traversing through the session,
and then produce the rows from that.
---
Wow that took longer than expected

@16:44 fix broken tests #timelog:00:07:56
we are missing an entity, apparently
---
Actually, it was the test that was wrong. There were only 7 items
in the particular session, the 8th item was the start of a new session.
I was comparing against the whole list of entities, not the session
itself.

@17:04 what is left? logtags, SessionRow, ConnectionsRow, end-to-end #timelog:00:08:26
I need a logtags row. that doesn't even exist
---
"dayblurb" row is archaic. Should just be called "Session"
---
The SessionRow is not yet created yet.
---
A session should also be able to have blocks attached to it,
though that hasn't been implemented yet.
---
The connections row has yet to be populated.
---
I need to start getting actual lines parsed into statements.
Maybe make a StatementBuilder?
---
The actual SQLite code generators need to start being made as well.

@17:14 end to end architecture #timelog:00:03:06
We have a file that is opened, or something from standard input
---
The input is read line by line. This is used to produce a list
of statements.
---
Statements get turned into an entity list.
---
The entity list gets turned into a list of Session Trees.
---
The session trees and entity list are used together to form
a list of session rows.
---
Each grouping of session rows are turned in to SQLite code,
and this is printed to standard output.

@18:28 set up connections row #timelog:00:27:03
I want connections to have deterministic output. So, I'm making
the connections map a BTreeMap.
---
We could make the connections sorted too, but this should
already be deterministic. They will appear in insertion order,
relative to the node they are associated with.

@18:56 time for tags #timelog:00:12:45
should be very similar to connections

@19:10 make SessionRow work #timelog:00:12:54

@19:31 set up simple file IO in main #timelog:00:11:14

@19:43 statement builder #timelog:00:12:32

@19:57 set up the initial pipeline right up to SQLite code #timelog:00:18:21

@20:18 code generation for SQLite is the last thing left I think #timelog:00:05:36
what's that going to look like?
---
top level, each SessionRows thing is going to have a genenerate trait.
Those will call generate for each of the rows types in the table.
---
I think it's about time to have an end-to-end test file that
builds the actual SQLite file and runs queries.
---
We can build this up incrementally I think. The top-level generate
funciton can slowly populate more and more of the tables.

@21:05 build the initial top-level generation method #timelog:00:15:28
From there, the underyling SQLite tables can be built up
one by one.
---
I forgot to make titles option in the statement parser.
I think I can fix that.

@21:30 bugs with statementbuidler nice #timelog:00:09:27

@21:34 make titles optional in statements #timelog:00:21:58

@22:02 attempt to generate an entity list table #timelog:00:26:31
We got an entity table!
---
Before I make more tables, I'd like to make it so this log actually parses.
I think the one gotcha I have here are that blocks aren't yet able
to attach to the start of sessions.

@2025-08-26#logzet Last day of this initial logzet effort

@10:04 hoping to wrap things up today. what is left? #timelog:00:03:11
I want to be able to finish up generating all the SQLite table data.
---
I want to make sure that blocks are set up for SQLite full-text search.
---
I want sessions to have blocks associated with them.
---
My goal is to be able to parse this log by the end of the data.
If the data isn't all there, that's fine. But I'd like it to
be close. I'd like this syntax to be valid. I think that will
set me up for success later this fall when I will have little
to no time to update this thing.

@10:08 sessions should definitely have blocks associated with them #timelog:00:53:04
We can update the session tree for this. the old session data
structure can wait (maybe remove it even?).
---
Our session builder needs to be updated to clear the currently
selected entry key when a new session is created. Somewhere,
this will provide the logic needed in order append the
block to the session instead of the block. Doesn't sound terribly
difficult, but it might require a fixing a handful of things.
---
I think it will be prudent to build a small unit test for this.
The abstractions should make it easy to spin this up.
---
The session tree seems to be a reasonable place to set up this
test.
---
The test no longer panics. I've extended the InsertBlock trait
to specify inserting into the session or the entry. It doesn't
do anything yet for the session tree implementation. Now I need
to build some things out so the test fails again.
---
Good, now the tree is failing as expected. Let's see if I can
append blocks to the tree now.
---
The blocks are definitely being appended to, they just aren't
showing up in the final result.
---
Nice! tests pass. Will things parse okay now?
---
Oh hell yeah. It all parses now. Table generation, and then it
should be done.

@11:12 re-work SessionRow to include blocks #timelog:00:49:08
This seems like a good thing to look at after getting
blocks hooked up, because I think I'll be needing to tweak
the schema for this.
---
It looks like I didn't do any tests for SessionRow yet. I seem
to have put the bare minimum into it. Now that I've added
blocks to the SessionRow struct, I actually need to rework
the From trait to use the entity list like the other
from traits.

@12:07 sqlite table data generator for SessionRows #timelog:01:10:13
entity UUID lookup is going to be interesting.
---
I think the EntityList might still need to be a thing.
---
Thinking about it, I think it might actually make
sense to bake in the UUID into the row information.
Bringing the entity list back into the mix is a
messy abstraction. The memory hit will be fine.
---
this top block business... it also needs to be a UUID
that resolves to an entity row id.
---
This might be tough to add...

@13:43 introduce lookup table that maps EntityId to UUID #timelog:00:43:41
I was going to try and turn all EntityIds in the row data
into UUIDs. But, it turns out that this is tricky.
For the case of SessionIDs, knowing the UUID of the top
block is pretty much impossible because it has no idea
where the block is located (and there's no way to know
until the list is fully populated).
---
A lookup table is probably the cleanest way to resolve these UUIDs.
Make a lookup table in SessionRows, and then this table
can get passed around during table construction.
---
The lookup table isn't looking things up for some reason.
Troubleshooting.
---
I don't think I'm actually adding this block because
I didn't think to add blocks from sessions. There
might also be issues with the UUID generation.
It should show up as YYYY-MM-DD/N and that should
be distinct and unambiguous from entry UUIDs which
are YYYY-MM-DD/HH:MM
---
The UUIDs are now being generated! The blocks are still
not showing up. But that's because the logic in charge
of constructing the lookup table isn't being fed the
proper key.
---
Lookup table works!

@14:29 Entry table #timelog:00:22:03

@14:52 block table #timelog:00:16:57
I'm realizing this is where I'm going to want to do
full text search. So, I'll get it working for now,
but I'll want to circle back to make it FTS compatible.
It's 3pm now, and I think I need to be doing other things.
So, this will have to wait.
---
blocks from the session aren't showing up.
---
blocks have been added. no problem.

@15:11 now the connections #timelog:00:39:08
connections are not showing up
---
my connection data is garbage. Wrong number of
connections, plus the node information isn't being saved.
---
The connections btree map is being generated properly I think.
I'm just not generated the rows correctly. I thought
I was being clever with flattening.
---
Connections and entity lookup maps are global to all sessions.
Lumping them into SessionRows is redundant. Really, there
should be a struct on top of SessionRows that is the top-level
thing returned.
---
Connections need to be done after all the sessions
are populated, because there's no decent way to know
which connections belong to which sessions.
---
The ID is hard coded to be 0 for some reason. Am I not
setting it up right?
---
Ah yeah, I haven't implemented it yet.
---
Good! now to just run this once.
---
It works. It's messy. But, it works.

@16:45 logtags #timelog:00:20:38
Gotta have this for the timelogs.
---
You know, I think connections can be scoped
to sessions. An Entities list containing indices
for the session can be dynamically populated, and
then those can be used to build a connections
list. More copying, but it keeps the SessionRows
more self contained.
---
tags are not being found in my test
---
I don't think I fully finished up tags. Their
time has come.
---
Ah, I see it. Same issue I had with the lookup table.
Iterator indices versus entity Ids.
---
fixed and good to go.
---
Just gonna test with the bigger one.
---
Big one works

@17:28 make connections local to sessions #timelog:00:10:39
I think it'll be worth the extra legwork to scope
each lookup table to just entities in the session.
---
actually, I connections were broken anyways. the symbol
lookup table is only scoped for the current session.

17:41 add BEGIN/COMMIT #timelog:00:01:47

@17:43 remove dead_code annotations #timelog:00:11:59

@17:57 I think that's a wrap. I've done what I set out to do
The day is Tuesday. I was hoping to get this done on Sunday.
But, I got dragged into a pretty big restructuring to get
dagzet node connections working.
---
The full dagzet syntax still needs to be implemented,
and pre-block syntax needs to be worked out. These don't
feel as important to me (yet), as I can use the older
version of my log generator just fine for the legacy stuff.
---
Time to do something else.

@21:25 dagzet '$' operator how bad could it be? #timelog:00:36:24
I should be off this thing, but if I get this I think
I'll be feature complete with the original logging system
system.
---
Initial unit test set up. Failing as expected.
---
Note to my future self: it would have been faster to set up a test
that parses raw logzet text into statements (via StatementBuilder), but I instead opted
to handcoded the Statement enums themselves. The test goes
through less stacks this way.
